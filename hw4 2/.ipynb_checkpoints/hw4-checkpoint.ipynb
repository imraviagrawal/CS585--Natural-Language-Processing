{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4: CKY Algorithm and Dependency Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1: CKY Algorithm (30 points)\n",
    "\n",
    "In this section, you will implement the CKY algorithm for an unweighted CFG. See the starter code [cky.py](http://people.cs.umass.edu/~brenocon/inlp2017/hw4/cky.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 1.1 (8 points)\n",
    "Implement the acceptance version of CKY as ``cky_acceptance()``, which returns True if there is a ``S`` covering the entire sentence. Does it return True or False for the following sentences? Please ``pprint()`` the chart cells for each case as well. \n",
    "* the the\n",
    "* the table attacked a dog\n",
    "* the cat\n",
    "\n",
    "Hint: A simple way to implement the chart cells is by maintaining a list of nonterminals at the span. This list represents all possible nonterminals over that span. \n",
    "\n",
    "Hint: ``pprint()``ing the CKY chart cells may be useful for debugging.\n",
    "\n",
    "Hint: Python dictionaries allow tuples as keys. For example, ``d={}; d[(3,4)] = []``. A slight shortcut is that ``d[3,4]`` means the same thing as ``d[(3,4)]``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar rules in tuple form:\n",
      "[('S', ('NPZ', 'VP')),\n",
      " ('S', ('NP', 'VBZ')),\n",
      " ('NP', ('Det', 'Noun')),\n",
      " ('NPZ', ('Det', 'Nouns')),\n",
      " ('VP', ('Verb', 'NP')),\n",
      " ('VBZ', ('Verbs', 'NP')),\n",
      " ('PP', ('Prep', 'NP')),\n",
      " ('NP', ('NP', 'PP')),\n",
      " ('VP', ('VP', 'PP'))]\n",
      "Rule parents indexed by children:\n",
      "{('Det', 'Noun'): ['NP'],\n",
      " ('Det', 'Nouns'): ['NPZ'],\n",
      " ('NP', 'PP'): ['NP'],\n",
      " ('NP', 'VBZ'): ['S'],\n",
      " ('NPZ', 'VP'): ['S'],\n",
      " ('Prep', 'NP'): ['PP'],\n",
      " ('VP', 'PP'): ['VP'],\n",
      " ('Verb', 'NP'): ['VP'],\n",
      " ('Verbs', 'NP'): ['VBZ']}\n"
     ]
    }
   ],
   "source": [
    "import cky\n",
    "from pprint import pprint\n",
    "print \"Grammar rules in tuple form:\"\n",
    "pprint(cky.grammar_rules)\n",
    "print \"Rule parents indexed by children:\"\n",
    "pprint(cky.possible_parents_for_children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "the the\n",
      "{(0, 1): ['Det'], (0, 2): [], (1, 2): ['Det']}\n",
      "False\n",
      "********************************************************************************\n",
      "\n",
      " the table attacked a dog\n",
      "{(0, 1): ['Det'],\n",
      " (0, 2): ['NP'],\n",
      " (0, 3): [],\n",
      " (0, 4): [],\n",
      " (0, 5): ['S'],\n",
      " (1, 2): ['Noun'],\n",
      " (1, 3): [],\n",
      " (1, 4): [],\n",
      " (1, 5): [],\n",
      " (2, 3): ['Verbs'],\n",
      " (2, 4): [],\n",
      " (2, 5): ['VBZ'],\n",
      " (3, 4): ['Det'],\n",
      " (3, 5): ['NP'],\n",
      " (4, 5): ['Noun']}\n",
      "True\n",
      "********************************************************************************\n",
      "\n",
      " the cat\n",
      "{(0, 1): ['Det'], (0, 2): ['NP'], (1, 2): ['Noun']}\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#Print the result here\n",
    "import cky;reload(cky)\n",
    "print (\"*\"*80)\n",
    "print \"the the\"\n",
    "print cky.cky_acceptance([\"the\", \"the\"])\n",
    "print (\"*\"*80 + \"\\n\")\n",
    "print \"\\n the table attacked a dog\"\n",
    "print cky.cky_acceptance([\"the\", \"table\", \"attacked\", \"a\", \"dog\"])\n",
    "print (\"*\"*80)\n",
    "print \"\\n the cat\"\n",
    "print cky.cky_acceptance([\"the\", \"cat\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Question 1.2 (15 points)\n",
    "Implement the parsing version of CKY, which returns one of the legal parses for the sentence (and returns None if there are none). If there are multiple real parses, we don’t care which one you print. Implement this as `cky_parse()`. You probably want to start by copying your `cky_acceptance()` answer and modifying it. Have it return the parse in the following format, using nested lists to represent the tree (this is a simple Python variant of the Lisp-style S-expression that’s usually used for this.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "['S',\n",
    "        [['NP', [['Det', 'the'], ['Noun', 'cat']]],\n",
    "         ['VP', [['Verb', 'attacked'], \n",
    "                 ['NP', [['Det', 'the'], ['Noun', 'food']]]]]]]\n",
    "                 ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the parses for the following sentences.  \n",
    "* the cat saw a dog\n",
    "* the cat saw a dog in a table\n",
    "* the cat with a table attacked the food  \n",
    "\n",
    "Hint: In the chart cells, you will now have to store backpointers as well. One way to do it is to store a list of tuples, each of which is  ``(nonterminal, splitpoint, leftchild nonterm, rightchild nonterm)``. For example, if the state ``('NP', 3, 'Det', 'Noun')`` is in the cell for span (2,4), that means this is a chart state of symbol NP, which came from a ``Det`` at position (2,3) and a Noun at position (3,4).\n",
    "\n",
    "Hint: It may be useful to use a recursive function for the backtrace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "'Rejected'\n",
      "********************************************************************************\n",
      "'Rejected'\n",
      "********************************************************************************\n",
      "['S',\n",
      " [['NP',\n",
      "   [['NP', [['Det', 'the'], ['Noun', 'cat']]],\n",
      "    ['PP', [['Prep', 'with'], ['NP', [['Det', 'a'], ['Noun', 'table']]]]]]],\n",
      "  ['VBZ',\n",
      "   [['Verbs', 'attacked'], ['NP', [['Det', 'the'], ['Noun', 'food']]]]]]]\n"
     ]
    }
   ],
   "source": [
    "# Output the results for each sentence.\n",
    "#TODO: Print out the parse tree for each of the three sentence\n",
    "import cky;reload(cky)\n",
    "\n",
    "#pprint( cky.cky_parse(['the','cat','attacked','the','food']) )\n",
    "print \"*\" * 80\n",
    "pprint( cky.cky_parse(['the','cat','saw', 'a', 'dog']) )\n",
    "\n",
    "print \"*\" * 80\n",
    "pprint( cky.cky_parse(['the','cat','saw', 'a', 'dog', 'in', 'a', 'table']) )\n",
    "\n",
    "print \"*\" * 80\n",
    "pprint( cky.cky_parse(['the','cat','with','a','table','attacked','the','food']) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 1.3 (7 points)\n",
    "Revise the grammar as follows.\n",
    "\n",
    "* Add four words to the lexicon: two verbs “attack” and “attacks”, and the nouns “cats” and “dogs”.\n",
    "* Revise the rules to enforce subject-verb agreement on number.\n",
    "\n",
    "The new grammar should accept and reject the following sentences. Please run your parser on these sentences and report the parse trees for the accepted ones. Also, describe how you changed the grammar, and why.\n",
    "\n",
    "ACCEPT: ``the cat attacks the dog``   \n",
    "REJECT: ``the cat attack the dog``  \n",
    "ACCEPT: ``the cats attack the dog``  \n",
    "REJECT: ``the cat with the food on a dog attack the dog``\n",
    "\n",
    "Hint: you will need to introduce new nonterminal symbols, and modify the currently existing ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "['S',\n",
      " [['NP', [['Det', 'the'], ['Noun', 'cat']]],\n",
      "  ['VBZ', [['Verbs', 'attacks'], ['NP', [['Det', 'the'], ['Noun', 'dog']]]]]]]\n",
      "********************************************************************************\n",
      "'Rejected'\n",
      "********************************************************************************\n",
      "['S',\n",
      " [['NPZ', [['Det', 'the'], ['Nouns', 'cats']]],\n",
      "  ['VP', [['Verb', 'attack'], ['NP', [['Det', 'the'], ['Noun', 'dog']]]]]]]\n",
      "********************************************************************************\n",
      "'Rejected'\n",
      "********************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Output the results for each sentence.\n",
    "#TODO: Print out the parse tree for each of the four sentence\n",
    "import cky;reload(cky)\n",
    "print(\"*\"*80)\n",
    "pprint( cky.cky_parse(['the','cat','attacks','the','dog']) )\n",
    "print(\"*\"*80)\n",
    "pprint( cky.cky_parse(['the','cat','attack','the','dog']) )\n",
    "print(\"*\"*80)\n",
    "pprint( cky.cky_parse(['the','cats','attack','the','dog']) )\n",
    "print(\"*\"*80)\n",
    "pprint( cky.cky_parse(['the','cat','with', 'the', 'food', 'on', 'a', 'dog', 'attack','the','dog']) )\n",
    "print(\"*\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: Weighted CKY Algorithm (40 points)\n",
    "In this section you will implement the weighted CKY Algorithm for a Probabilistic CFG. You will have to make modifications to the existing algorithm to account for the probabilities and your parse function should output the most probable parse tree. \n",
    "Please write all your code in ``weighted_cky.py`` file for this section. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2.1 (7 points)\n",
    "The CKY Algorithm requires the CFG to be in Chomsky Normal Form. Convert the following CFG into Chomsky Normal Form. (For the sake of uniformity, replace the leftmost pairs of non-terminals with new non-terminal)\n",
    "\n",
    "S -> Aux NP VP   \n",
    "S -> VP  \n",
    "VP -> Verb NP  \n",
    "VP -> VP PP  \n",
    "Verb -> book  \n",
    "Aux -> does  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer here\n",
    "Using the Rules <br>\n",
    "A → BC,   or <br>\n",
    "A → a,   or <br>\n",
    "S → ε, <br>\n",
    "\n",
    "S -> ANP VP<br>\n",
    "S -> Verb NP<br>\n",
    "S -> VP PP<br>\n",
    "ANP -> Aux NP<br>\n",
    "Verb -> book<br>\n",
    "Aux -> does<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2.2 (8 points)\n",
    "We will now implement a weighted CYK algorithm to parse a sentence and return the most probable parse tree. \n",
    "The grammar is defined in ``pcfg_grammar_original.txt``. As you can notice, some of the rules are not in CNF. \n",
    "Modify the ``pcfg_grammar_modified.txt`` file such that all the rules are in Chomsky Normal Form.\n",
    "(For the sake of uniformity, replace the leftmost pairs of non-terminals with new non-terminal)\n",
    "\n",
    "Note: When transforming the grammar to CNF, must set production probabilities to preserve the probability of derivations.\n",
    "\n",
    "# ANSWER\n",
    "Please see the ``pcfg_grammar_modified.txt`` file to see the changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Question 2.3 (5 points)\n",
    "Explain briefly what are the changes you made to convert the grammar into CNF Form. Why did you make these changes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer here\n",
    "\n",
    "Using the Chomsky Normal Rules:- \n",
    "\n",
    "A → BC,   or <br>\n",
    "A → a,   or <br>\n",
    "S → ε, <br>\n",
    "\n",
    "converted the non terminal rules to the new non terminal rules. I converted any non terminal rules like A -> BCD to A-> ED and E -> BC, Also any grammer rules like A -> B and B -> a becomes A -> a."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2.4 (8 points)\n",
    "Complete the ``populate_grammar_rules()`` function in the ``weighted_cky.py`` script. This function will have to read in the grammar rules from ``pcfg_grammar_modified.txt`` file and populate the `grammar_rules` and `lexicon` data structure. Additionally you would need to store the probability mapping in a suitable data structure. \n",
    "\n",
    "Hint: You can modify the starter code provided in cky.py for this task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************************************************************\n",
      "Grammar rules in tuple form:\n",
      "************************************************************\n",
      "\n",
      "[('S', ('NP', 'VP', '0.8')),\n",
      " ('S', ('ANP', 'VP', '0.1')),\n",
      " ('S', ('Verb', 'NP', '0.05')),\n",
      " ('S', ('VP', 'PP', '0.03')),\n",
      " ('ANP', ('Aux', 'NP', '1.0')),\n",
      " ('NP', ('Det', 'Nominal', '0.6')),\n",
      " ('Nominal', ('Nominal', 'Noun', '0.2')),\n",
      " ('Nominal', ('Nominal', 'PP', '0.5')),\n",
      " ('VP', ('Verb', 'NP', '0.5')),\n",
      " ('VP', ('VP', 'PP', '0.3')),\n",
      " ('PP', ('Prep', 'NP', '1.0')),\n",
      " ('Det', ('the', '0.6')),\n",
      " ('Det', ('a', '0.2')),\n",
      " ('Det', ('that', '0.1')),\n",
      " ('Det', ('this', '0.1')),\n",
      " ('Noun', ('book', '0.1')),\n",
      " ('Noun', ('flight', '0.5')),\n",
      " ('Noun', ('meal', '0.2')),\n",
      " ('Noun', ('money', '0.2')),\n",
      " ('Nominal', ('book', '0.03')),\n",
      " ('Nominal', ('flight', '0.15')),\n",
      " ('Nominal', ('meal', '0.06')),\n",
      " ('Nominal', ('money', '0.06')),\n",
      " ('Verb', ('book', '0.5')),\n",
      " ('Verb', ('include', '0.2')),\n",
      " ('Verb', ('prefer', '0.3')),\n",
      " ('VP', ('book', '0.1')),\n",
      " ('VP', ('include', '0.04')),\n",
      " ('VP', ('prefer', '0.06')),\n",
      " ('S', ('book', '0.01')),\n",
      " ('S', ('include', '0.004')),\n",
      " ('S', ('prefer', '0.006')),\n",
      " ('Pronoun', ('I', '0.5')),\n",
      " ('Pronoun', ('he', '0.1')),\n",
      " ('Pronoun', ('she', '0.1')),\n",
      " ('Pronoun', ('me', '0.3')),\n",
      " ('NP', ('I', '0.1')),\n",
      " ('NP', ('he', '0.02')),\n",
      " ('NP', ('she', '0.02')),\n",
      " ('NP', ('me', '0.06')),\n",
      " ('Proper-Noun', ('Houston', '0.8')),\n",
      " ('Proper-Noun', ('NWA', '0.2')),\n",
      " ('NP', ('Houston', '0.16')),\n",
      " ('NP', ('NWA', '0.04')),\n",
      " ('Aux', ('does', '1.0')),\n",
      " ('Prep', ('from', '0.25')),\n",
      " ('Prep', ('to', '0.25')),\n",
      " ('Prep', ('on', '0.1')),\n",
      " ('Prep', ('near', '0.2')),\n",
      " ('Prep', ('through', '0.2'))]\n",
      "\n",
      "************************************************************\n",
      "Rule parents indexed by children:\n",
      "************************************************************\n",
      "\n",
      "{('ANP', 'VP'): ['S'],\n",
      " ('Aux', 'NP'): ['ANP'],\n",
      " ('Det', 'Nominal'): ['NP'],\n",
      " ('NP', 'VP'): ['S'],\n",
      " ('Nominal', 'Noun'): ['Nominal'],\n",
      " ('Nominal', 'PP'): ['Nominal'],\n",
      " ('Prep', 'NP'): ['PP'],\n",
      " ('VP', 'PP'): ['S', 'VP'],\n",
      " ('Verb', 'NP'): ['S', 'VP']}\n",
      "\n",
      "************************************************************\n",
      "probabilities\n",
      "************************************************************\n",
      "\n",
      "{('ANP', 'Aux', 'NP'): 1.0,\n",
      " ('Aux', 'does'): 1.0,\n",
      " ('Det', 'a'): 0.2,\n",
      " ('Det', 'that'): 0.1,\n",
      " ('Det', 'the'): 0.6,\n",
      " ('Det', 'this'): 0.1,\n",
      " ('NP', 'Det', 'Nominal'): 0.6,\n",
      " ('NP', 'Houston'): 0.16,\n",
      " ('NP', 'I'): 0.1,\n",
      " ('NP', 'NWA'): 0.04,\n",
      " ('NP', 'he'): 0.02,\n",
      " ('NP', 'me'): 0.06,\n",
      " ('NP', 'she'): 0.02,\n",
      " ('Nominal', 'Nominal', 'Noun'): 0.2,\n",
      " ('Nominal', 'Nominal', 'PP'): 0.5,\n",
      " ('Nominal', 'book'): 0.03,\n",
      " ('Nominal', 'flight'): 0.15,\n",
      " ('Nominal', 'meal'): 0.06,\n",
      " ('Nominal', 'money'): 0.06,\n",
      " ('Noun', 'book'): 0.1,\n",
      " ('Noun', 'flight'): 0.5,\n",
      " ('Noun', 'meal'): 0.2,\n",
      " ('Noun', 'money'): 0.2,\n",
      " ('PP', 'Prep', 'NP'): 1.0,\n",
      " ('Prep', 'from'): 0.25,\n",
      " ('Prep', 'near'): 0.2,\n",
      " ('Prep', 'on'): 0.1,\n",
      " ('Prep', 'through'): 0.2,\n",
      " ('Prep', 'to'): 0.25,\n",
      " ('Pronoun', 'I'): 0.5,\n",
      " ('Pronoun', 'he'): 0.1,\n",
      " ('Pronoun', 'me'): 0.3,\n",
      " ('Pronoun', 'she'): 0.1,\n",
      " ('Proper-Noun', 'Houston'): 0.8,\n",
      " ('Proper-Noun', 'NWA'): 0.2,\n",
      " ('S', 'ANP', 'VP'): 0.1,\n",
      " ('S', 'NP', 'VP'): 0.8,\n",
      " ('S', 'VP', 'PP'): 0.03,\n",
      " ('S', 'Verb', 'NP'): 0.05,\n",
      " ('S', 'book'): 0.01,\n",
      " ('S', 'include'): 0.004,\n",
      " ('S', 'prefer'): 0.006,\n",
      " ('VP', 'VP', 'PP'): 0.3,\n",
      " ('VP', 'Verb', 'NP'): 0.5,\n",
      " ('VP', 'book'): 0.1,\n",
      " ('VP', 'include'): 0.04,\n",
      " ('VP', 'prefer'): 0.06,\n",
      " ('Verb', 'book'): 0.5,\n",
      " ('Verb', 'include'): 0.2,\n",
      " ('Verb', 'prefer'): 0.3}\n",
      "\n",
      "************************************************************\n",
      "Lexicon\n",
      "************************************************************\n",
      "\n",
      "{'Aux': ['does'],\n",
      " 'Det': ['the', 'a', 'that', 'this'],\n",
      " 'NP': ['I', 'he', 'she', 'me', 'Houston', 'NWA'],\n",
      " 'Nominal': ['book', 'flight', 'meal', 'money'],\n",
      " 'Noun': ['book', 'flight', 'meal', 'money'],\n",
      " 'Prep': ['from', 'to', 'on', 'near', 'through'],\n",
      " 'Pronoun': ['I', 'he', 'she', 'me'],\n",
      " 'Proper-Noun': ['Houston', 'NWA'],\n",
      " 'S': ['book', 'include', 'prefer'],\n",
      " 'VP': ['book', 'include', 'prefer'],\n",
      " 'Verb': ['book', 'include', 'prefer']}\n"
     ]
    }
   ],
   "source": [
    "import weighted_cky; reload(weighted_cky)\n",
    "from weighted_cky import populate_grammar_rules\n",
    "populate_grammar_rules()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2.5 (12 points)\n",
    "Implement the weighted parsing version of CKY, which returns the most probable legal parse for the sentence (and returns None if there are none). If there are multiple real parses, this function will always return the most probable parse i.e the one with maximum probability. \n",
    "Complete the ``pcky_parse()``.\n",
    "Print the parse tree and the probabilities for the following sentences:\n",
    "* book the flight through Houston\n",
    "* include this book\n",
    "* the the\n",
    "\n",
    "Hint: You can use the code in `cky_parse()` and modify it to accomodate probabilities and compute the most probable parse.   \n",
    "Note: The topmost cell should contain rules associated with the `S` non terminal, if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "['S',\n",
      " [['Verb', 'book'],\n",
      "  ['NP',\n",
      "   [['Det', 'the'],\n",
      "    ['Nominal',\n",
      "     [['Nominal', 'flight'],\n",
      "      ['PP', [['Prep', 'through'], ['NP', 'Houston']]]]]]]]]\n",
      "\n",
      "********************************************************************************\n",
      "[None]\n",
      "********************************************************************************\n",
      "\n",
      "['S', [['Verb', 'include'], ['NP', [['Det', 'this'], ['Nominal', 'book']]]]]\n",
      "********************************************************************************\n"
     ]
    }
   ],
   "source": [
    "import weighted_cky; reload(weighted_cky)\n",
    "from weighted_cky import pcky_parse\n",
    "populate_grammar_rules()\n",
    "# Output the results for each sentence.\n",
    "#TODO: Print out the parse tree for each of the three sentence\n",
    "print(\"*\"*80)\n",
    "pprint(pcky_parse(['book','the', 'flight', 'through', 'Houston']) )\n",
    "print(\"\\n\" + \"*\"*80)\n",
    "pprint( pcky_parse(['the','the']) )\n",
    "print(\"*\"*80 + \"\\n\")\n",
    "pprint( pcky_parse(['include','this', 'book']) )\n",
    "print \"*\" * 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3: Dependency parser output (30 points)\n",
    "\n",
    "You will conduct manual error analysis of [CoreNLP](https://stanfordnlp.github.io/CoreNLP/)'s dependency parser.\n",
    "\n",
    "Create an English sentence where the parser makes an error, and you know what the correct analysis ought to be, according to the Universal Dependencies grammatical standard.  You will want to play around with different sentences, look at their output, and check against the Universal Dependencies annotation standard.  The current version of CoreNLP outputs according to the \"UD version 1\" standard, so please use this page:\n",
    " * [UD v1 homepage](http://universaldependencies.org/docsv1/)\n",
    " * and in particular, the [UD v1 dependency relations list](http://universaldependencies.org/docsv1/u/dep/index.html)\n",
    "\n",
    "For quickly looking at things, their [online demo](http://corenlp.run/) may be useful.\n",
    "\n",
    "However, for this assignment, you need to run the parser to output in \"conllu\" format, which is human readable.  You need to download and run the parser for this.  (It requires Java.) Use version 3.8.0 (it should be the current version). You can it working in interactive mode so you can just type sentences into it on the terminal like this:\n",
    "\n",
    "```\n",
    "./corenlp.sh -annotators tokenize,ssplit,pos,lemma,depparse -outputFormat conllu \n",
    "[...]\n",
    "Entering interactive shell. Type q RETURN or EOF to quit.\n",
    "NLP> \n",
    "```\n",
    "\n",
    "For example then you can type\n",
    "```\n",
    "NLP> I saw a cat.\n",
    "1       I       I       _       PRP     _       2       nsubj   _       _\n",
    "2       saw     see     _       VBD     _       0       root    _       _\n",
    "3       a       a       _       DT      _       4       det     _       _\n",
    "4       cat     cat     _       NN      _       2       dobj    _       _\n",
    "5       .       .       _       .       _       2       punct   _       _\n",
    "```\n",
    "\n",
    "You can also use the `-inputFile` flag if you'd rather give it a whole file at once.\n",
    "\n",
    "As you can see in the parser documentation, the 7th and 8th columns describe the dependency edge for the word's parent (a.k.a governor): it has the index of its parent, and the edge label (a.k.a. the relation).  For example, this parse contains the dependency edge *nsubj(saw:2, I:1)* meaning that \"I\" is the subject of \"saw\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1:** Once you've decided your sentence, please put the conllu-formatted parser output below in the markdown triple-quoted area.  Please be very careful where it goes since we will use a script to pull it out.\n",
    "    \n",
    "PARSE GOES BELOW HERE\n",
    "```\n",
    "1\the\the\t_\tPRP\t_\t2\tnsubj\t_\t_\n",
    "2\truns\trun\t_\tVBZ\t_\t0\troot\t_\t_\n",
    "3\tlike\tlike\t_\tIN\t_\t5\tcase\t_\t_\n",
    "4\ta\ta\t_\tDT\t_\t5\tdet\t_\t_\n",
    "5\tdeer\tdeer\t_\tNNS\t_\t2\tnmod\t_\t_\n",
    "6\tand\tand\t_\tCC\t_\t5\tcc\t_\t_\n",
    "7\ttiger\ttiger\t_\tNN\t_\t8\tcompound\t_\t_\n",
    "8\truns\trun\t_\tNNS\t_\t5\tconj\t_\t_\n",
    "9\tlike\tlike\t_\tIN\t_\t11\tcase\t_\t_\n",
    "10\ta\ta\t_\tDT\t_\t11\tdet\t_\t_\n",
    "11\tcat\tcat\t_\tNN\t_\t5\tnmod\t_\t_\n",
    "```\n",
    "PARSE GOES ABOVE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2:** Please describe the error you found.  Also give a citation and link to the relevant part of the UD documentation describing one of the relations that the parser predicted in error, or did something wrong with.\n",
    "\n",
    "ANSWER: The Sentence I am using here is \"\"he runs like a tiger a deer and tiger runs like a cat. <br>\n",
    "       The error is in the case of second runs, where CoreNLP dependency parser indentifies the runs as the conj of deer. Conjuction (conj) is used used in case of sentences like Bill is big and honest. But in my sentence case the runs is not conj of the deer. The second \"runs\" should be connected to the tiger as root.\n",
    "       \n",
    "       Citation of Conj:\n",
    "       http://universaldependencies.org/docsv1/u/dep/conj.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Question 3.3:** Please give correct that error in the parse .  Put your corrected parse, again in that conllu textual format, below.  You should take a copy of the output and manually change some of the 7th/8th dependency edge columns.\n",
    "\n",
    "PARSE GOES BELOW HERE\n",
    "```\n",
    "1\the\the\t_\tPRP\t_\t2\tnsubj\t_\t_\n",
    "2\truns\trun\t_\tVBZ\t_\t0\troot\t_\t_\n",
    "3\tlike\tlike\t_\tIN\t_\t5\tcase\t_\t_\n",
    "4\ta\ta\t_\tDT\t_\t5\tdet\t_\t_\n",
    "5\tdeer\tdeer\t_\tNNS\t_\t2\tnmod\t_\t_\n",
    "6\t.\t.\t_\t.\t_\t2\tpunct\t_\t_\n",
    "\n",
    "1\ttiger\ttiger\t_\tNN\t_\t2\tcompound\t_\t_\n",
    "2\truns\trun\t_\tNNS\t_\t0\troot\t_\t_\n",
    "3\tlike\tlike\t_\tIN\t_\t5\tcase\t_\t_\n",
    "4\ta\ta\t_\tDT\t_\t5\tdet\t_\t_\n",
    "5\tcat\tcat\t_\tNN\t_\t2\tnmod\t_\t_\n",
    "\n",
    "```\n",
    "PARSE GOES ABOVE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.4:** Please describe your correction and why it solves the error.\n",
    "\n",
    "ANSWER: So, Adding the puntuation in the middle of the sentence corrects the parser confusion. The parser outputs the second runs as the root on the tiget as conpared to conju of the deer in the case of first dependency parser case.\n",
    "\n",
    "SO, adding puntuation breaks the sentence and helping the parser to clear the confusion."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
