{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5: Lexicons and Distributional Semantics\n",
    "\n",
    "This is due on **Friday, 11/10 (11pm)** \n",
    "\n",
    "## How to do this problem set\n",
    "\n",
    "Most of these questions require writing Python code and computing results, and the rest of them have textual answers.  Write all the textual answers in this document, show the output of your experiment in this document, and implement the functions in the `python` files. \n",
    "\n",
    "Submit a PDF of thie .ipynb to Gradescope, and the .ipynb and all python files to Moodle.\n",
    "\n",
    "The assignment has two parts:\n",
    " * In the first part, you will experiment with Turney's method to find word polarities in a twitter dataset, given some positive and negative seed words.\n",
    " * In the second part, you will experiment with distributional and vector semantics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Name: <>**\n",
    "\n",
    "**List collaborators, and how you collaborated, here:** (see our [grading and policies page](http://people.cs.umass.edu/~brenocon/inlp2017/grading.html) for details on our collaboration policy).\n",
    "\n",
    "* _name 1_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initiallizing seed list\n",
    "pos_seed_list = [\"good\", \"nice\", \"love\", \"excellent\", \"fortunate\", \"correct\", \"superior\"]\n",
    "neg_seed_list = [\"bad\", \"nasty\", \"poor\", \"hate\", \"unfortunate\", \"wrong\", \"inferior\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Lexicon semantics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Recall that PMI of a pair of words, is defined as:\n",
    "\n",
    "$$PMI(x, y) = log\\frac{ P(x, y) }{ P(x)P(y)}$$\n",
    "\n",
    "The Turney method defines a word's polarity as:\n",
    "\n",
    "$$Polarity(word) = PMI(word, positive\\_word)‚àíPMI(word, negative\\_word)$$\n",
    "\n",
    "where the joint probability $P(w, v)$ or, more specifically, $P(w\\ NEAR\\ v)$ is the probability of both being \"near\" each other.  We'll work with twe\n",
    "ets, so it means: if you choose a tweet at random, what's the chance it contains both `w` and `v`?\n",
    "\n",
    "(If you look at the Turney method as explained in the SLP3 chapter, the \"hits\" function is a count of web pages that contain at least one instance of the two words occurring near each other.)\n",
    "\n",
    "The positive_word and negative_word terms are initially constructed by hand. For example: we might start with single positive word ('excellent') and a single negative word ('bad'). We can also have list of positive words ('excellent', 'perfect', 'love', ....) and list of negative words ('bad', 'hate', 'filthy',....)\n",
    "\n",
    "If we're using a seed list of multiple terms, just combine them into a single symbol, e.g. all the positive seed words get rewritten to POS_WORD (and similarly for NEG_WORD).  This $P(w, POS\\_WORD)$ effectively means the co-ocurrence of $w$ with any of the terms in the list.\n",
    "\n",
    "For this assignment, we will use twitter dataset which has 349378 tweets. These tweets are in the file named `tweets.txt`. These are the tweets of one day and filtered such that each tweet contains at least one of the seed words we've selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (15 points)\n",
    "\n",
    "The file `tweets.txt` contains around 349,378 tweets with one tweet per line.  It is a random sample of public tweets, which we tokenized with [twokenize.py's tokenizeRawTweetText()](https://github.com/myleott/ark-twokenize-py/blob/master/twokenize.py)). The text you see has a space between each token so you can just use `.split()` if you want.  We also filtered tweets to ones that included at least one term from one of these seed lists:\n",
    "* Positive seed list: [\"good\", \"nice\", \"love\", \"excellent\", \"fortunate\", \"correct\", \"superior\"]\n",
    "* Negative seed list: [\"bad\", \"nasty\", \"poor\", \"hate\", \"unfortunate\", \"wrong\", \"inferior\"]\n",
    "\n",
    "Each tweet contains at least one positive or negative seed word. Take a look at the file (e.g. `less' and `grep'). Implement the Turney's method to calculate polarity scores of all words.\n",
    "\n",
    "Some things to keep in mind:\n",
    "* Ignore the seed words (i.e. don't calculate the polarity of the seed words).\n",
    "* You may want to ignore the polarity of words beignning with `@` or `#`. \n",
    "\n",
    "We recommend that you write code in a python file, but it's up to you.\n",
    "\n",
    "QUESTION: You'll have to do something to handle zeros in the PMI equation. Please explain your and justify your decision about this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**textual answer here**\n",
    "We have to handle zero in two places in the PMI equation, first in the denominator part of the equation, because $1/0$ is $infinity$ and $log(infinity)$ is undefined. Also, we have to manage zero in the numerator because $log(0)$ is undefined as well. Here I am adding hyperparameter alpha in the PMI equation which is 1 if not defined something else by the user. So, by adding one to numerator and denominator it will make sure that the equation never have to face zero and if the counts are not zero or the PMI does not have to handle zero, 1 is divided by the large number in this case N (number of tweets) and it will not effect the calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Question 2 (5 points)\n",
    "\n",
    "Print the top 50 most-positive words (i.e. inferred positive words) and the 50 most-negative words.\n",
    "\n",
    "Many of the words won't make sense.  Comment on at least two that do make sense, and at least two that don't.  Why do you think these are happening with this dataset and method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The len of the tweets.txt 174689\n"
     ]
    }
   ],
   "source": [
    "from helper import *\n",
    "import operator\n",
    "tweets = readfile('tweets.txt')\n",
    "positive_negative_word, word_counts = count(tweets, pos_seed_list, neg_seed_list)\n",
    "#result = polarity(tweets, positive_count, negative_count, word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pol = polarity(tweets, positive_negative_word, word_counts, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******50 Most Positive Words*******\n",
      "Hello 11.0919143693\n",
      "evening 10.8681847088\n",
      "Birthday 10.5744836465\n",
      "‚ù§Ô∏è 10.1568442365\n",
      "üëç 9.73556708457\n",
      "‚ô° 9.10267909553\n",
      "‚ù§ 8.86277886853\n",
      "March 8.61008247481\n",
      "craze 8.58598835231\n",
      "Happy 8.47378796666\n",
      "Thanks 8.39456779064\n",
      "23 8.35409200989\n",
      "lovely 8.25532031711\n",
      "USATour2017 8.20827702712\n",
      "AlwaysJaDine 8.20105677914\n",
      "birthday 8.10131383339\n",
      "thank 8.07709194188\n",
      "kindness 7.98896801146\n",
      "Thank 7.97577312632\n",
      "üòò 7.94104327357\n",
      "Lauren 7.86954285832\n",
      "\\n\\nPanaloMOTO 7.80775900809\n",
      "Congrats 7.80404567297\n",
      "London 7.7327116277\n",
      "üòç‚ù§ 7.7260841315\n",
      "BIRTHDAY 7.61599344146\n",
      "First 7.57808326914\n",
      ":D 7.43313294637\n",
      "makeup 7.41415800878\n",
      "Morning 7.38961189488\n",
      "ol 7.33721161848\n",
      "üòä 7.13152587805\n",
      "Team 7.12273295005\n",
      "movie 7.07586073155\n",
      "HAPPY 7.06616259857\n",
      "hood 7.06242077942\n",
      "wonderful 7.02614021438\n",
      "goodnight 6.96858227023\n",
      "xx 6.91960826563\n",
      "flowers 6.9117698173\n",
      "üíï 6.80351749099\n",
      "practice 6.77195160545\n",
      "collection 6.76437591993\n",
      "Check 6.76385925756\n",
      "thanks 6.74669315928\n",
      "ji 6.71726784195\n",
      "they'd 6.70364607372\n",
      "nd 6.65910892777\n",
      "üôèüèª 6.64659288428\n",
      "shall 6.64057735244\n",
      "Justin 6.62197413259\n",
      "\n",
      "********50 Most Negative Words**********\n",
      "crimes -11.3414343952\n",
      "closure -9.67914113146\n",
      "suggesting -9.67009129594\n",
      "violence -9.00793928311\n",
      "they\\ -8.81182440418\n",
      "presidency -8.66442511978\n",
      "claims -8.60327965229\n",
      "moods -8.58078620993\n",
      "disability -8.46003944554\n",
      "cigarettes -8.45698600805\n",
      "violent -8.18848675502\n",
      "Obamacare -8.16311407584\n",
      "un‚Ä¶ -8.11949388353\n",
      "families -8.09240208182\n",
      "explain -8.08934659007\n",
      "sick -8.06172233069\n",
      "despicable -7.97104122482\n",
      "Pelosi -7.94660389977\n",
      "POC -7.87573104501\n",
      "vandalism -7.73383140272\n",
      "habit -7.71402877542\n",
      "victims -7.69340948822\n",
      "blaming -7.65704184405\n",
      "Saf‚Ä¶ -7.64211619383\n",
      "threats -7.55437727952\n",
      "Obama‚Äôs -7.48577012344\n",
      "Crime -7.46870221493\n",
      "Worse -7.46399632389\n",
      "diary\\ -7.44654941029\n",
      "gonna‚Ä¶ -7.44654941029\n",
      "designed -7.41494407087\n",
      "JCCs -7.39567707991\n",
      "Victims -7.37182586409\n",
      "generals -7.30659744986\n",
      "centers -7.30036690011\n",
      "botc‚Ä¶ -7.27978619241\n",
      "passed -7.1888144142\n",
      "raid -7.08653556508\n",
      "leak -7.07722334879\n",
      "crime -7.0439525327\n",
      "https://t.co/ELGdDnERnv -6.98005960034\n",
      "Latino -6.95944031314\n",
      "responsibility -6.92567345067\n",
      "condemn -6.88933074695\n",
      "Oh -6.88589053246\n",
      "annual -6.85716146402\n",
      "DeVos -6.81016056355\n",
      "anti-Semitism -6.80789041501\n",
      "justify -6.80789041501\n",
      "anti-Semitic -6.79824811752\n",
      "JCC -6.78954127634\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "most_positive = sorted(pol.items(), key=operator.itemgetter(1), reverse=True)\n",
    "most_negative = sorted(pol.items(), key=operator.itemgetter(1))\n",
    "count = 0\n",
    "print \"******50 Most Positive Words*******\"\n",
    "for word,val in most_positive:\n",
    "    print word, val\n",
    "    count+=1\n",
    "    if count > 50:\n",
    "        break\n",
    "\n",
    "count = 0\n",
    "\n",
    "print \"\\n********50 Most Negative Words**********\"\n",
    "for word,val in most_negative:\n",
    "    print word, val\n",
    "    count+=1\n",
    "    if count > 50:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Textual answer here.\n",
    "The Word ‚ù§Ô∏è, Thanks, Birthday in the Positive words make sense also, words like condemn, crime and violance is making sense in the negative words. \n",
    "    \n",
    "These are the words which defines the positiveness or negativeness of the data, for example If we are wishing birthday to someone:-  \n",
    "\n",
    "                              \"Wishing you happy birthday\"\n",
    " Also The word Condemn being negative makes sense, given example:\n",
    "                        \n",
    "              \"I condemn the unfortuniate terorist attacks in the humanity\"\n",
    "         \n",
    "The words like nd, they are ending up in the positive words and words like familes, gonna they are not making sense. \n",
    "    \n",
    "The word like nd are more neutral than negative, for example the If I am using the wishing someone birthday wish I may use nd, \n",
    "           \n",
    "                 \"Wishing you very very happy birthday nd have a blast today\"\n",
    "or another example of nd can be\n",
    "      \n",
    "      \"I wish you were never born mr p. you are such shame nd unforunate for this world\"\n",
    "                 \n",
    "Also, Word like families and gonna are again more neutral than negative like \n",
    "        \n",
    "        \"This families on vacations will the best this gonna happen this break\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (5 points)\n",
    "\n",
    "Now filter out all the words which have total count < 500, and then print top 50 polarity words and bottom 50 polarity words. \n",
    "\n",
    "Choose some of the words from both the sets of 50 words you got above which accoording to you make sense. Again please note, you will find many words which don't make sense. Do you think these results are better than the results you got in Question-1? Explain why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******* Most Positive Words after filetering *******\n",
      "\n",
      "‚ù§Ô∏è 10.1568442365\n",
      "‚ù§ 8.86277886853\n",
      "Happy 8.47378796666\n",
      "Thanks 8.39456779064\n",
      "birthday 8.10131383339\n",
      "thank 8.07709194188\n",
      "Thank 7.97577312632\n",
      "ol 7.33721161848\n",
      "üòä 7.13152587805\n",
      "movie 7.07586073155\n",
      "hood 7.06242077942\n",
      "thanks 6.74669315928\n",
      "Von 6.45513884392\n",
      "Be 6.38227196063\n",
      "Taylor 6.10532106971\n",
      "soon 6.0919510928\n",
      "follow 6.026388402\n",
      "morning 5.94340750638\n",
      "Teyana 5.92851632067\n",
      "üòç 5.79106129583\n",
      "Keef 5.76199166336\n",
      "https://t.co/I46MhN5tag 5.76199166336\n",
      "Herban 5.76199166336\n",
      "https://t.co/inU4PQoS7z 5.7481346287\n",
      "üòÇüòÇüòÇüòç 5.7481346287\n",
      "happy 5.59693919737\n",
      "Always 5.54769646434\n",
      "!! 5.42125628289\n",
      "best 5.40545499507\n",
      "Have 5.32223187847\n",
      "amazing 5.30010990617\n",
      "beautiful 5.29740428689\n",
      ":) 5.16042751999\n",
      "far 4.96262048409\n",
      "speech 4.84964465446\n",
      "together 4.80478848749\n",
      "heard 4.71328843313\n",
      "today 4.69827760769\n",
      "Decay 4.66452550662\n",
      "night 4.60012997205\n",
      "work 4.59827345801\n",
      "miss 4.58587175315\n",
      "God 4.56653210251\n",
      "friends 4.55107175138\n",
      "luck 4.52914376234\n",
      "! 4.50622093762\n",
      "pregnancy 4.46952366465\n",
      "learn 4.37325879806\n",
      "giving 4.35788535187\n",
      "fall 4.35565704008\n",
      "President 4.33882887758\n",
      "\n",
      "******* Most Negative Words after filetering *******\n",
      "\n",
      "crimes -11.3414343952\n",
      "cigarettes -8.45698600805\n",
      "explain -8.08934659007\n",
      "Saf‚Ä¶ -7.64211619383\n",
      "crime -7.0439525327\n",
      "Oh -6.88589053246\n",
      "CHILD -6.54350390516\n",
      "ugly -6.52962938954\n",
      "store -6.44339274539\n",
      "used -6.31611098992\n",
      "condemning -6.26759436894\n",
      "gets -5.81953486801\n",
      "marijuana -5.76941648508\n",
      "feel -5.7603551075\n",
      "stands -5.68549759768\n",
      "woman -5.56288709735\n",
      "evil -5.52007207225\n",
      "ME -5.45721648501\n",
      "hell -5.36928161882\n",
      "women -5.36209593953\n",
      "something -5.22521113894\n",
      "When -5.0624679646\n",
      "its -5.02411321777\n",
      "want -4.89041293301\n",
      "sorry -4.82779032053\n",
      "ppl -4.80728352087\n",
      "make -4.7668013538\n",
      "sad -4.70387895519\n",
      "united -4.58612472876\n",
      "Dems -4.56259663505\n",
      "Democrats -4.55903363901\n",
      "üò≠ -4.46456309607\n",
      "Why -4.36733110629\n",
      "bc -4.12388925509\n",
      "school -4.10779613239\n",
      "when -3.92662307735\n",
      "after -3.8970257752\n",
      "food -3.84593083754\n",
      "shit -3.80818716277\n",
      "without -3.76495982826\n",
      "won't -3.72918710162\n",
      "hurt -3.71460240841\n",
      "against -3.67638245493\n",
      "ask -3.67458047847\n",
      "away -3.67312896468\n",
      "ass -3.64857538743\n",
      "idea -3.59431030118\n",
      "getting -3.55046173756\n",
      "there -3.51561523659\n",
      "going -3.48690288272\n",
      "w -3.45892921957\n"
     ]
    }
   ],
   "source": [
    "# Write code to print words here\n",
    "count = 0\n",
    "print \"\\n******* Most Positive Words after filetering *******\\n\"\n",
    "for word,val in most_positive:\n",
    "    if word_counts[word] >= 500:\n",
    "        print word, val\n",
    "        count+=1\n",
    "    if count > 50:\n",
    "        break\n",
    "\n",
    "count = 0\n",
    "print \"\\n******* Most Negative Words after filetering *******\\n\"\n",
    "for word,val in most_negative:\n",
    "    if word_counts[word] >= 500:\n",
    "        print word, val\n",
    "        count+=1\n",
    "    if count > 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Textual answer here.\n",
    "\n",
    "Yes, this results look better than the previous results. for example if we see the first word of the most positive word now is a  ‚ù§Ô∏è than hello as a previous case. Hello is more neutral word, it can be used to both positive and negative conversations \"Hello mister please mind your own bussiness.\" \n",
    "\n",
    "This is happining because when we are filtering out words which have frequency less than 500, This are the words which might have appeared in the one class than other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 (5 points)\n",
    "\n",
    "Even after filtering out words with count < 500, many top-most and bottom-most polarity don't make sense. Identify what kind of words these are and what can be done to filter them out. You can read some tweets in the file to see what's happening. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Textual answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-2: Distributional Semantics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that, where $i$ indexes over the context types, cosine similarity is defined as follows. $x$ and $y$ are both vectors of context counts (each for a different word), where $x_i$ is the count of context $i$.\n",
    "\n",
    "$$cossim(x,y) = \\frac{ \\sum_i x_i y_i }{ \\sqrt{\\sum_i x_i^2} \\sqrt{\\sum_i y_i^2} }$$\n",
    "\n",
    "The nice thing about cosine similarity is that it is normalized: no matter what the input vectors are, the output is between 0 and 1. One way to think of this is that cosine similarity is just, um, the cosine function, which has this property (for non-negative $x$ and $y$). Another way to think of it is, to work through the situations of maximum and minimum similarity between two context vectors, starting from the definition above.\n",
    "\n",
    "Note: a good way to understand the cosine similarity function is that the numerator cares about whether the $x$ and $y$ vectors are correlated. If $x$ and $y$ tend to have high values for the same contexts, the numerator tends to be big. The denominator can be thought of as a normalization factor: if all the values of $x$ are really large, for example, dividing by the square root of their sum-of-squares prevents the whole thing from getting arbitrarily large. In fact, dividing by both these things (aka their norms) means the whole thing can‚Äôt go higher than 1.\n",
    "\n",
    "In this problem we'll work with vectors of raw context counts.  (As you know, this is not necessarily the best representation.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 (5 points)\n",
    "\n",
    "See the file `nytcounts.university_cat_dog`, which contains context count vectors for three words: ‚Äúdog‚Äù, ‚Äúcat‚Äù, and ‚Äúuniversity‚Äù. These are immediate left and right contexts from a New York Times corpus. You can open the file in a text editor since it‚Äôs quite small. \n",
    "\n",
    "Write a function which takes context count dictionaries of two words and calculates cosine similarity between these two words. The function should return a number beween 0 and 1.  Briefly comment on whether the relative simlarities make sense.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file nytcounts.university_cat_dog has contexts for 3 words\n",
      "Cosine Similarity between dog and cat is:- 0.966891672715\n",
      "Cosine Similarity between dog and university is:- 0.659230248969\n",
      "Cosine Similarity between cat and university is:- 0.660442421144\n"
     ]
    }
   ],
   "source": [
    "import distsim;\n",
    "from distsim import *; \n",
    "reload(distsim)\n",
    "\n",
    "word_to_ccdict = distsim.load_contexts(\"nytcounts.university_cat_dog\")\n",
    "# write code here to show output (i.e. cosine similarity between these words.)\n",
    "# We encourage you to write other functions in distsim.py itself. \n",
    "print \"Cosine Similarity between dog and cat is:- \" + str(cosine_similarity(word_to_ccdict['cat'], word_to_ccdict['dog']))\n",
    "print \"Cosine Similarity between dog and university is:- \" + str(cosine_similarity(word_to_ccdict['dog'], word_to_ccdict['university']))\n",
    "print \"Cosine Similarity between cat and university is:- \" + str(cosine_similarity(word_to_ccdict['university'], word_to_ccdict['cat']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write your response here:**\n",
    "\n",
    "The cobosine similatity here is making a lot of sense. The Cosine Similarity of dog and cat is high given they both are pet. At the same time the cosine similarity of dog and university is comparatively low compared to dog and cat. The same is true for the cat and University is low comparitively of cosine similarity of dog and cat.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Question 6 (20 points)\n",
    "\n",
    "Explore similarities in `nytcounts.4k`, which contains context counts for about 4000 words in a sample of New York Times articles. The news data was lowercased and URLs were removed. The context counts are for the 2000 most common words in twitter, as well as the most common 2000 words in the New York Times. (But all context counts are from New York Times.) The context counts only contain contexts that appeared for more than one word.  The file has three tab-separate fields: the word, its count, and a JSON-encoded dictionary of its context counts.  You'll see it's just counts of the immediate left/right neighbors.\n",
    "\n",
    "Choose **six** words. For each, show the output of 20 nearest words (use cosine similarity as distance metric). Comment on whether the output makes sense. Comment on whether this approach to distributional similarity makes more or less sense for certain terms.\n",
    "Four of your words should be:\n",
    "\n",
    " * a name (for example: person, organization, or location)\n",
    " * a common noun\n",
    " * an adjective\n",
    " * a verb\n",
    "\n",
    "You may also want to try exploring further words that are returned from a most-similar list from one of these. You can think of this as traversing the similarity graph among words.\n",
    "\n",
    "*Implementation note:* \n",
    "On my laptop it takes several hundred MB of memory to load it into memory from the `load_contexts()` function. If you don‚Äôt have enough memory available, your computer will get very slow because the OS will start swapping. If you have to use a machine without that much memory available, you can instead implement in a streaming approach by using the `stream_contexts()` generator function to access the data; this lets you iterate through the data from disk, one vector at a time, without putting everything into memory. You can see its use in the loading function. (You could also alternatively use a key-value or other type of database, but that‚Äôs too much work for this assignment.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'jack' # name\n",
    "'jacob' #name\n",
    "'paris' # location\n",
    "'school' # common noun\n",
    "'small' #adjective\n",
    "'eat' #verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file nytcounts.4k has contexts for 3648 words\n",
      "\n",
      "******* Most 20 most nearest Words to jack*******\n",
      "\n",
      "Word = adam and similarity score = 0.879731849466\n",
      "Word = james and similarity score = 0.859791406534\n",
      "Word = susan and similarity score = 0.856596258738\n",
      "Word = daniel and similarity score = 0.847600400729\n",
      "Word = jonathan and similarity score = 0.847532173876\n",
      "Word = peter and similarity score = 0.844088466095\n",
      "Word = eric and similarity score = 0.843254808498\n",
      "Word = elizabeth and similarity score = 0.843212500388\n",
      "Word = andrew and similarity score = 0.837502134837\n",
      "Word = max and similarity score = 0.837313367421\n",
      "Word = sam and similarity score = 0.83688492819\n",
      "Word = nancy and similarity score = 0.830201308889\n",
      "Word = david and similarity score = 0.829875534881\n",
      "Word = mark and similarity score = 0.825521704605\n",
      "Word = justin and similarity score = 0.824285104081\n",
      "Word = thomas and similarity score = 0.815153479018\n",
      "Word = steven and similarity score = 0.813399333271\n",
      "Word = henry and similarity score = 0.812411403854\n",
      "Word = anthony and similarity score = 0.811830749816\n",
      "Word = chris and similarity score = 0.80986022039\n",
      "\n",
      "******* Most 20 most nearest Words to jacob*******\n",
      "\n",
      "Word = max and similarity score = 0.813965842441\n",
      "Word = elizabeth and similarity score = 0.806544520035\n",
      "Word = henry and similarity score = 0.804164548253\n",
      "Word = jack and similarity score = 0.801694099024\n",
      "Word = honey and similarity score = 0.798835438606\n",
      "Word = adam and similarity score = 0.790081764384\n",
      "Word = nike and similarity score = 0.78891744236\n",
      "Word = daniel and similarity score = 0.78817841634\n",
      "Word = ohio and similarity score = 0.779273537938\n",
      "Word = james and similarity score = 0.777941467705\n",
      "Word = justin and similarity score = 0.77404249882\n",
      "Word = jonathan and similarity score = 0.763223493263\n",
      "Word = nyc and similarity score = 0.762117040948\n",
      "Word = sam and similarity score = 0.760830731607\n",
      "Word = susan and similarity score = 0.760426508974\n",
      "Word = chelsea and similarity score = 0.760023820961\n",
      "Word = thomas and similarity score = 0.756037290295\n",
      "Word = 2006 and similarity score = 0.753955937751\n",
      "Word = 34 and similarity score = 0.750406409181\n",
      "Word = peter and similarity score = 0.749200628067\n",
      "\n",
      "******* Most 20 most nearest Words to paris*******\n",
      "\n",
      "Word = london and similarity score = 0.969922701547\n",
      "Word = 2000 and similarity score = 0.968934319714\n",
      "Word = washington and similarity score = 0.96828475993\n",
      "Word = 2002 and similarity score = 0.967796233302\n",
      "Word = iraq and similarity score = 0.966823178859\n",
      "Word = 1996 and similarity score = 0.963882680837\n",
      "Word = baghdad and similarity score = 0.963814951823\n",
      "Word = 2003 and similarity score = 0.963786580068\n",
      "Word = 1999 and similarity score = 0.962656787032\n",
      "Word = 1994 and similarity score = 0.962015475578\n",
      "Word = 1998 and similarity score = 0.96077176855\n",
      "Word = 1995 and similarity score = 0.958196421648\n",
      "Word = 1997 and similarity score = 0.95818436422\n",
      "Word = europe and similarity score = 0.952949847717\n",
      "Word = manhattan and similarity score = 0.951685479875\n",
      "Word = jail and similarity score = 0.94647319085\n",
      "Word = 2001 and similarity score = 0.945579132203\n",
      "Word = atlanta and similarity score = 0.942767464066\n",
      "Word = afghanistan and similarity score = 0.930968363416\n",
      "Word = september and similarity score = 0.930786955273\n",
      "\n",
      "******* Most 20 most nearest Words to school*******\n",
      "\n",
      "Word = schools and similarity score = 0.741096505683\n",
      "Word = college and similarity score = 0.716161495973\n",
      "Word = line and similarity score = 0.694353893027\n",
      "Word = church and similarity score = 0.692936169261\n",
      "Word = practice and similarity score = 0.692639540488\n",
      "Word = experience and similarity score = 0.68964261712\n",
      "Word = location and similarity score = 0.686896635079\n",
      "Word = scenes and similarity score = 0.684265543442\n",
      "Word = standards and similarity score = 0.68314025111\n",
      "Word = movement and similarity score = 0.682270236675\n",
      "Word = structure and similarity score = 0.681240519859\n",
      "Word = pain and similarity score = 0.680551450596\n",
      "Word = club and similarity score = 0.679799771917\n",
      "Word = star and similarity score = 0.679519599857\n",
      "Word = trial and similarity score = 0.679030536708\n",
      "Word = character and similarity score = 0.677712663217\n",
      "Word = success and similarity score = 0.676811960686\n",
      "Word = painting and similarity score = 0.676032739005\n",
      "Word = language and similarity score = 0.673658144796\n",
      "Word = land and similarity score = 0.67138577287\n",
      "\n",
      "******* Most 20 most nearest Words to small*******\n",
      "\n",
      "Word = large and similarity score = 0.973071412011\n",
      "Word = huge and similarity score = 0.966526892445\n",
      "Word = rare and similarity score = 0.956221558428\n",
      "Word = brief and similarity score = 0.954411767655\n",
      "Word = single and similarity score = 0.951555186585\n",
      "Word = lovely and similarity score = 0.949123911397\n",
      "Word = wonderful and similarity score = 0.948595362466\n",
      "Word = strong and similarity score = 0.945712206547\n",
      "Word = terrible and similarity score = 0.944205014338\n",
      "Word = tiny and similarity score = 0.94333832508\n",
      "Word = special and similarity score = 0.942158289015\n",
      "Word = giant and similarity score = 0.938978542916\n",
      "Word = sharp and similarity score = 0.938243642381\n",
      "Word = little and similarity score = 0.923994722037\n",
      "Word = fake and similarity score = 0.921158607603\n",
      "Word = strange and similarity score = 0.920161059203\n",
      "Word = massive and similarity score = 0.919302821476\n",
      "Word = broad and similarity score = 0.919022436256\n",
      "Word = good and similarity score = 0.917984664425\n",
      "Word = brilliant and similarity score = 0.917552275558\n",
      "\n",
      "******* Most 20 most nearest Words to eat*******\n",
      "\n",
      "Word = marry and similarity score = 0.964286212821\n",
      "Word = shoot and similarity score = 0.963193255852\n",
      "Word = hide and similarity score = 0.957670012765\n",
      "Word = stop and similarity score = 0.950446757708\n",
      "Word = sell and similarity score = 0.94898678915\n",
      "Word = kill and similarity score = 0.943214395262\n",
      "Word = buy and similarity score = 0.943124990767\n",
      "Word = teach and similarity score = 0.942295899732\n",
      "Word = treat and similarity score = 0.941038126628\n",
      "Word = win and similarity score = 0.93881787636\n",
      "Word = grow and similarity score = 0.937942644236\n",
      "Word = steal and similarity score = 0.935536117618\n",
      "Word = help and similarity score = 0.935124282998\n",
      "Word = watch and similarity score = 0.935064832836\n",
      "Word = write and similarity score = 0.933830419085\n",
      "Word = pass and similarity score = 0.933271069578\n",
      "Word = burn and similarity score = 0.932247421537\n",
      "Word = produce and similarity score = 0.931072999276\n",
      "Word = draw and similarity score = 0.929059048589\n",
      "Word = hear and similarity score = 0.926286772812\n"
     ]
    }
   ],
   "source": [
    "import distsim; reload(distsim)\n",
    "word_to_ccdict = distsim.load_contexts(\"nytcounts.4k\")\n",
    "print \"\\n******* Most 20 most nearest Words to jack*******\\n\"\n",
    "distsim.show_nearest(word_to_ccdict, word_to_ccdict['jack'],set(['jack']),distsim.cosine_similarity)\n",
    "\n",
    "print \"\\n******* Most 20 most nearest Words to jacob*******\\n\"\n",
    "distsim.show_nearest(word_to_ccdict, word_to_ccdict['jacob'],set(['jacob']),distsim.cosine_similarity)\n",
    "\n",
    "print \"\\n******* Most 20 most nearest Words to paris*******\\n\"\n",
    "distsim.show_nearest(word_to_ccdict, word_to_ccdict['paris'],set(['paris']),distsim.cosine_similarity)\n",
    "\n",
    "print \"\\n******* Most 20 most nearest Words to school*******\\n\"\n",
    "distsim.show_nearest(word_to_ccdict, word_to_ccdict['school'],set(['school']),distsim.cosine_similarity)\n",
    "\n",
    "print \"\\n******* Most 20 most nearest Words to small*******\\n\"\n",
    "distsim.show_nearest(word_to_ccdict, word_to_ccdict['small'],set(['small']),distsim.cosine_similarity)\n",
    "\n",
    "print \"\\n******* Most 20 most nearest Words to eat*******\\n\"\n",
    "distsim.show_nearest(word_to_ccdict, word_to_ccdict['eat'],set(['eat']),distsim.cosine_similarity)\n",
    "\n",
    "###Provide your answer below; perhaps in another cell so you don't have to reload the data each time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7 (10 points)\n",
    "\n",
    "In the next several questions, you'll examine similarities in trained word embeddings, instead of raw context counts.\n",
    "\n",
    "See the file `nyt_word2vec.university_cat_dog`, which contains word embedding vectors pretrained by word2vec [1] for three words: ‚Äúdog‚Äù, ‚Äúcat‚Äù, and ‚Äúuniversity‚Äù, from the same corpus. You can open the file in a text editor since it‚Äôs quite small.\n",
    "\n",
    "Write a function which takes word embedding vectors of two words and calculates cossine similarity between these 2 words. The function should return a number beween -1 and 1. Briefly comment on whether the relative simlarities make sense. \n",
    "\n",
    "*Implementation note:*\n",
    "Notice that the inputs of this function are numpy arrays (v1 and v2). If you are not very familiar with the basic operation in numpy, you can find some examples in the basic operation section here:\n",
    "https://docs.scipy.org/doc/numpy-dev/user/quickstart.html\n",
    "\n",
    "If you know how to use Matlab but haven't tried numpy before, the following link should be helpful:\n",
    "https://docs.scipy.org/doc/numpy-dev/user/numpy-for-matlab-users.html\n",
    "\n",
    "[1] Mikolov, Tomas, et al. \"Distributed representations of words and phrases and their compositionality.\" NIPS 2013."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between dog and cat is:- 0.827517295965\n",
      "Cosine Similarity between dog and university is:- -0.190753135501\n",
      "Cosine Similarity between cat and university is:- -0.205394745036\n"
     ]
    }
   ],
   "source": [
    "import distsim; reload(distsim)\n",
    "\n",
    "word_to_vec_dict = distsim.load_word2vec(\"nyt_word2vec.university_cat_dog\")\n",
    "print \"Cosine Similarity between dog and cat is:- \" + str(distsim.cos_sim(word_to_vec_dict['cat'], word_to_vec_dict['dog']))\n",
    "print \"Cosine Similarity between dog and university is:- \" + str(distsim.cos_sim(word_to_vec_dict['dog'], word_to_vec_dict['university']))\n",
    "print \"Cosine Similarity between cat and university is:- \" + str(distsim.cos_sim(word_to_vec_dict['university'], word_to_vec_dict['cat']))\n",
    " \n",
    "# write code here to show output (i.e. cosine similarity between these words.)\n",
    "# We encourage you to write other functions in distsim.py itself. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write your response here:**\n",
    "\n",
    "As mentioned above, The cosine similatity here is making a lot of sense. The Cosine Similarity of dog and cat is high given they both are pet. At the same time the cosine similarity of dog and university is comparatively low compared to dog and cat. The same is true for the cat and University is low comparitively of cosine similarity of dog and cat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8 (20 points)\n",
    "\n",
    "Repeat the process you did in the question 6, but now use dense vector from word2vec. Comment on whether the outputs makes sense. Compare the outputs of using nearest words on word2vec and the outputs on sparse context vector (so we suggest you to use the same words in question 6). Which method works better on the query words you choose. Please brief explain why one method works better than other in each case.\n",
    "\n",
    "Not: we used the default parameters of word2vec in [gensim](https://radimrehurek.com/gensim/models/word2vec.html) to get word2vec word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******* Most 20 most nearest Words to jack*******\n",
      "\n",
      "Word = sam and similarity score = 0.804650868501\n",
      "Word = jim and similarity score = 0.784263389501\n",
      "Word = adam and similarity score = 0.777474342932\n",
      "Word = ed and similarity score = 0.775161593077\n",
      "Word = chris and similarity score = 0.770623148763\n",
      "Word = anthony and similarity score = 0.759454281466\n",
      "Word = bruce and similarity score = 0.748197814965\n",
      "Word = brian and similarity score = 0.745924331721\n",
      "Word = steve and similarity score = 0.744650198971\n",
      "Word = ray and similarity score = 0.744424710639\n",
      "Word = bob and similarity score = 0.740298867859\n",
      "Word = jonathan and similarity score = 0.739568545763\n",
      "Word = matt and similarity score = 0.738397895777\n",
      "Word = larry and similarity score = 0.729699086832\n",
      "Word = daniel and similarity score = 0.729641022873\n",
      "Word = josh and similarity score = 0.72950135195\n",
      "Word = jeff and similarity score = 0.728281357786\n",
      "Word = alan and similarity score = 0.727446889115\n",
      "Word = eric and similarity score = 0.722989518866\n",
      "Word = gary and similarity score = 0.722301102389\n",
      "\n",
      "******* Most 20 most nearest Words to jacob*******\n",
      "\n",
      "Word = elizabeth and similarity score = 0.846903711683\n",
      "Word = max and similarity score = 0.836984459923\n",
      "Word = clifford and similarity score = 0.828206166377\n",
      "Word = leo and similarity score = 0.825521942265\n",
      "Word = k. and similarity score = 0.8141050643\n",
      "Word = susan and similarity score = 0.804036295633\n",
      "Word = andrew and similarity score = 0.801292418996\n",
      "Word = jonathan and similarity score = 0.781430133583\n",
      "Word = t. and similarity score = 0.780036398061\n",
      "Word = henry and similarity score = 0.777814773613\n",
      "Word = adam and similarity score = 0.771475584181\n",
      "Word = b. and similarity score = 0.768043166594\n",
      "Word = lawrence and similarity score = 0.767618660228\n",
      "Word = anthony and similarity score = 0.764368520289\n",
      "Word = justin and similarity score = 0.763949007361\n",
      "Word = barbara and similarity score = 0.762113229322\n",
      "Word = jay and similarity score = 0.757096729658\n",
      "Word = robin and similarity score = 0.75676982718\n",
      "Word = edward and similarity score = 0.755632189535\n",
      "Word = daniel and similarity score = 0.75370633517\n",
      "\n",
      "******* Most 20 most nearest Words to paris*******\n",
      "\n",
      "Word = london and similarity score = 0.742107827129\n",
      "Word = spain and similarity score = 0.634463364795\n",
      "Word = australia and similarity score = 0.623465314272\n",
      "Word = italy and similarity score = 0.595381536063\n",
      "Word = france and similarity score = 0.58273759425\n",
      "Word = la and similarity score = 0.546190042754\n",
      "Word = germany and similarity score = 0.535940620503\n",
      "Word = el and similarity score = 0.531092441066\n",
      "Word = argentina and similarity score = 0.526052579318\n",
      "Word = madrid and similarity score = 0.522976187947\n",
      "Word = chelsea and similarity score = 0.522678936055\n",
      "Word = hotel and similarity score = 0.517737491196\n",
      "Word = chicago and similarity score = 0.504221789448\n",
      "Word = restaurant and similarity score = 0.497719991719\n",
      "Word = japan and similarity score = 0.485197298741\n",
      "Word = royal and similarity score = 0.469962805048\n",
      "Word = 1960 and similarity score = 0.466812750658\n",
      "Word = del and similarity score = 0.465245854511\n",
      "Word = 1996 and similarity score = 0.465106626993\n",
      "Word = de and similarity score = 0.46145017425\n",
      "\n",
      "******* Most 20 most nearest Words to school*******\n",
      "\n",
      "Word = schools and similarity score = 0.75222831832\n",
      "Word = college and similarity score = 0.749073141248\n",
      "Word = class and similarity score = 0.62663670792\n",
      "Word = student and similarity score = 0.580021551051\n",
      "Word = classes and similarity score = 0.55825512395\n",
      "Word = columbia and similarity score = 0.546274281597\n",
      "Word = teacher and similarity score = 0.536806366718\n",
      "Word = academy and similarity score = 0.534093683027\n",
      "Word = university and similarity score = 0.515488570733\n",
      "Word = students and similarity score = 0.511512873819\n",
      "Word = education and similarity score = 0.511472003069\n",
      "Word = harvard and similarity score = 0.5090504665\n",
      "Word = tech and similarity score = 0.50430522084\n",
      "Word = math and similarity score = 0.503104202652\n",
      "Word = teaching and similarity score = 0.493482811826\n",
      "Word = teachers and similarity score = 0.486860886982\n",
      "Word = princeton and similarity score = 0.485218743452\n",
      "Word = yale and similarity score = 0.469128724487\n",
      "Word = gym and similarity score = 0.467681661412\n",
      "Word = degree and similarity score = 0.452242066307\n",
      "\n",
      "******* Most 20 most nearest Words to small*******\n",
      "\n",
      "Word = large and similarity score = 0.872116601448\n",
      "Word = tiny and similarity score = 0.740835894895\n",
      "Word = vast and similarity score = 0.664048960627\n",
      "Word = huge and similarity score = 0.641445380654\n",
      "Word = smaller and similarity score = 0.626264603893\n",
      "Word = big and similarity score = 0.58646670179\n",
      "Word = larger and similarity score = 0.583728744062\n",
      "Word = separate and similarity score = 0.554064402132\n",
      "Word = massive and similarity score = 0.550263049553\n",
      "Word = wide and similarity score = 0.514304266979\n",
      "Word = private and similarity score = 0.508697739441\n",
      "Word = broad and similarity score = 0.506540355212\n",
      "Word = steel and similarity score = 0.501893723321\n",
      "Word = traditional and similarity score = 0.496682179926\n",
      "Word = mostly and similarity score = 0.495191384289\n",
      "Word = variety and similarity score = 0.475786275018\n",
      "Word = limited and similarity score = 0.47191176752\n",
      "Word = heavy and similarity score = 0.471686086364\n",
      "Word = rare and similarity score = 0.468135909424\n",
      "Word = significant and similarity score = 0.467857634805\n",
      "\n",
      "******* Most 20 most nearest Words to eat*******\n",
      "\n",
      "Word = drink and similarity score = 0.765148798351\n",
      "Word = enjoy and similarity score = 0.711493132019\n",
      "Word = sleep and similarity score = 0.706877663891\n",
      "Word = feed and similarity score = 0.685293152453\n",
      "Word = breathe and similarity score = 0.673759067476\n",
      "Word = wear and similarity score = 0.670034287822\n",
      "Word = forget and similarity score = 0.658329445839\n",
      "Word = ate and similarity score = 0.65470653416\n",
      "Word = burn and similarity score = 0.634897570213\n",
      "Word = get and similarity score = 0.614431792198\n",
      "Word = eating and similarity score = 0.613962036626\n",
      "Word = treat and similarity score = 0.60318544897\n",
      "Word = smell and similarity score = 0.603163870658\n",
      "Word = buy and similarity score = 0.602649048162\n",
      "Word = listen and similarity score = 0.595459586665\n",
      "Word = sit and similarity score = 0.594974533206\n",
      "Word = see and similarity score = 0.587573346075\n",
      "Word = cook and similarity score = 0.585612527119\n",
      "Word = stick and similarity score = 0.581404640223\n",
      "Word = hang and similarity score = 0.580721791486\n"
     ]
    }
   ],
   "source": [
    "import distsim\n",
    "word_to_vec_dict = distsim.load_word2vec(\"nyt_word2vec.4k\")\n",
    "print \"\\n******* Most 20 most nearest Words to jack*******\\n\"\n",
    "distsim.show_nearest(word_to_vec_dict, word_to_vec_dict['jack'],set(['jack']),distsim.cos_sim)\n",
    "\n",
    "print \"\\n******* Most 20 most nearest Words to jacob*******\\n\"\n",
    "distsim.show_nearest(word_to_vec_dict, word_to_vec_dict['jacob'],set(['jacob']),distsim.cos_sim)\n",
    "\n",
    "print \"\\n******* Most 20 most nearest Words to paris*******\\n\"\n",
    "distsim.show_nearest(word_to_vec_dict, word_to_vec_dict['paris'],set(['paris']),distsim.cos_sim)\n",
    "\n",
    "print \"\\n******* Most 20 most nearest Words to school*******\\n\"\n",
    "distsim.show_nearest(word_to_vec_dict, word_to_vec_dict['school'],set(['school']),distsim.cos_sim)\n",
    "\n",
    "print \"\\n******* Most 20 most nearest Words to small*******\\n\"\n",
    "distsim.show_nearest(word_to_vec_dict, word_to_vec_dict['small'],set(['small']),distsim.cos_sim)\n",
    "\n",
    "print \"\\n******* Most 20 most nearest Words to eat*******\\n\"\n",
    "distsim.show_nearest(word_to_vec_dict, word_to_vec_dict['eat'],set(['eat']),distsim.cos_sim)\n",
    "\n",
    "###Provide your answer below; perhaps in another cell so you don't have to reload the data each time\n",
    "###Provide your answer below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9 (15 points)\n",
    "An interesting thing to try with word embeddings is analogical reasoning tasks. In the following example, it's intended to solve the analogy question \"king is to man as what is to woman?\", or in SAT-style notation,\n",
    "\n",
    "king : man :: ____ : woman\n",
    "\n",
    "Some research has proposed to use additive operations on word embeddings to solve the analogy: take the vector $(v_{king}-v_{man}+v_{woman})$ and find the most-similar word to it.  One way to explain this idea: if you take \"king\", get rid of its attributes/contexts it shares with \"man\", and add in the attributes/contexts of \"woman\", hopefully you'll get to a point in the space that has king-like attributes but the \"man\" ones replaced with \"woman\" ones.\n",
    "\n",
    "Show the output for 20 closest words you get by trying to solve that analogy with this method.  Did it work?\n",
    "\n",
    "Please come up with another analogical reasoning task (another triple of words), and output the answer using the same method. Comment on whether the output makes sense. If the output makes sense, explain why we can capture such relation between words using an unsupervised algorithm. Where does the information come from? On the other hand, if the output does not make sense, propose an explanation why the algorithm fails on this case.\n",
    "\n",
    "\n",
    "Note that the word2vec is trained in an unsupervised manner just with distributional statistics; it is interesting that it can apparently do any reasoning at all.  For a critical view, see [Linzen 2016](http://www.aclweb.org/anthology/W/W16/W16-2503.pdf).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word = queen and similarity score = 0.725028631986\n",
      "Word = princess and similarity score = 0.577900103401\n",
      "Word = prince and similarity score = 0.566962392417\n",
      "Word = lord and similarity score = 0.530919391111\n",
      "Word = royal and similarity score = 0.520203296864\n",
      "Word = mary and similarity score = 0.497698146284\n",
      "Word = mama and similarity score = 0.495469636832\n",
      "Word = daughter and similarity score = 0.493757946566\n",
      "Word = singer and similarity score = 0.489838082014\n",
      "Word = kim and similarity score = 0.488354695243\n",
      "Word = elizabeth and similarity score = 0.482484843405\n",
      "Word = girl and similarity score = 0.477338294808\n",
      "Word = grandma and similarity score = 0.476990726681\n",
      "Word = sister and similarity score = 0.470304371825\n",
      "Word = mother and similarity score = 0.469422028833\n",
      "Word = clark and similarity score = 0.46824004741\n",
      "Word = wedding and similarity score = 0.46233629356\n",
      "Word = husband and similarity score = 0.456851188179\n",
      "Word = boyfriend and similarity score = 0.447550574504\n",
      "Word = jesus and similarity score = 0.438572115806\n"
     ]
    }
   ],
   "source": [
    "# Write code to show output here.\n",
    "import distsim\n",
    "king = word_to_vec_dict['king']\n",
    "man = word_to_vec_dict['man']\n",
    "woman = word_to_vec_dict['woman']\n",
    "distsim.show_nearest(word_to_vec_dict,\n",
    "                     king-man+woman,\n",
    "                     set(['king','man','woman']),\n",
    "                     distsim.cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word = germany and similarity score = 0.852228240177\n",
      "Word = britain and similarity score = 0.796347823164\n",
      "Word = europe and similarity score = 0.780507381157\n",
      "Word = italy and similarity score = 0.780123880453\n",
      "Word = spain and similarity score = 0.744563107146\n",
      "Word = india and similarity score = 0.741158443781\n",
      "Word = russia and similarity score = 0.71760613491\n",
      "Word = australia and similarity score = 0.689681638742\n",
      "Word = argentina and similarity score = 0.680727627136\n",
      "Word = china and similarity score = 0.680026975466\n",
      "Word = canada and similarity score = 0.637877286391\n",
      "Word = america and similarity score = 0.61665435954\n",
      "Word = european and similarity score = 0.605925266688\n",
      "Word = africa and similarity score = 0.605411548357\n",
      "Word = ukraine and similarity score = 0.59694393205\n",
      "Word = afghanistan and similarity score = 0.586397734305\n",
      "Word = french and similarity score = 0.573833854437\n",
      "Word = paris and similarity score = 0.570905710291\n",
      "Word = iran and similarity score = 0.555832473756\n",
      "Word = german and similarity score = 0.542073014482\n"
     ]
    }
   ],
   "source": [
    "japan = word_to_vec_dict['japan']\n",
    "brazil = word_to_vec_dict['brazil']\n",
    "france = word_to_vec_dict['france']\n",
    "distsim.show_nearest(word_to_vec_dict,\n",
    "                     japan-brazil+france,\n",
    "                     set(['japan','brazil','france']),\n",
    "                     distsim.cos_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Textual answer here.\n",
    "\n",
    "Yes the output is making sense in the above analogy, the result should be list of contries, which the word2vec model is return flawlessly. The model learns to map each discrete word id (0 through the number of words in the vocabulary) into a low-dimensional continuous vector-space from their distributional properties observed in some raw text corpus. Geometrically, one may interpret these vectors as tracing out points on the outside surface of a manifold in the \"embedded space\". \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
